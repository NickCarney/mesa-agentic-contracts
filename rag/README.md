
  
# Retrieval-Augmented Generation (RAG) Agent

This Python application is a **Retrieval-Augmented Generation (RAG) agent** that processes documents stored in a Google Cloud Storage (GCS) bucket, vectorizes them, and allows users to query the documents using a deployed API. The agent uses Google Vertex AI for embeddings and language model inference.

## Features

- Automatically fetches all files from a specified GCS bucket.
- Splits documents into manageable chunks for processing.
- Builds a vector store using embeddings generated by Vertex AI Embeddings.
- Provides an HTTP API endpoint for querying the vectorized documents using Vertex AI's large language model (LLM).
- Designed to be deployed on **Google Cloud Run** for scalability and ease of use.

---

## How It Works

1. **Document Processing**:
   - The script retrieves all files from a specified Google Cloud Storage bucket.
   - Each file is loaded, split into smaller chunks, and converted into embeddings using Google Vertex AI Embeddings.
   - All embeddings are stored in an in-memory vector store (Chroma).

2. **Query Handling**:
   - The Flask API exposes an endpoint (`/query`) where users can send questions about the documents.
   - The agent retrieves relevant chunks from the vector store and uses Vertex AI's LLM to generate answers.

3. **Deployment**:
   - The application is containerized using Docker and deployed on Google Cloud Run.
   - The service URL allows users to interact with the agent via HTTP requests.

---

## Prerequisites

1. **Python Environment**:
   - Python 3.9 or later
   - Install dependencies listed in `requirements.txt`.

2. **Google Cloud Setup**:
   - A Google Cloud project with the following APIs enabled:
     - Vertex AI API
     - Cloud Run API
     - Cloud Storage API
   - A GCS bucket containing your documents (e.g., PDF files).
   - Proper IAM permissions to access GCS and Vertex AI resources.

3. **Docker**:
   - Docker installed locally for containerization.

---

## Running Locally

### Steps to Run Locally

1. Clone the repository:

    git clone https://github.com/NickCarney/mesa-agentic-contracts.git
	cd mesa-agentic-contracts

2. Install dependencies:
pip install -r requirements.txt

3. Set up your Google Cloud credentials:
Ensure you have authenticated with Google Cloud CLI and set up your credentials:
gcloud auth application-default login

4. Update environment variables:
Set up your Google Cloud project ID, region, and GCS bucket name in the script or as environment variables.

5. Run the application locally:
python rag.py


6. Test the API locally:
Use `curl` or Postman to send queries to the local server:
curl -X POST http://127.0.0.1:8080/query
-H "Content-Type: application/json"
-d '{"question": "What is my contract split according to the contract?"}'


---

## Deployment on Google Cloud Run

### Steps to Deploy

1. Build the Docker image:
docker push gcr.io/eth-global/rag-image

2. Push the Docker image to Google Container Registry (GCR). (Include the period in the command):
docker buildx build -t gcr.io/eth-global/rag-image .

3. Deploy the container on Google Cloud Run:
gcloud run deploy eth-global-service --image gcr.io/eth-global/rag-image --platform managed --region us-central1 --memory 1Gi

4. Note the service URL provided after deployment.

5. Test the deployed service:
Use `curl` or Postman to send queries to your service URL:
curl -X POST https://[SERVICE-URL]/query
-H "Content-Type: application/json"
-d '{"question": "What is my contract split according to the contract?"}'
---

## Script Overview

### Key Components

1. **Document Loader**:
 Automatically fetches all files from a specified GCS bucket using `google.cloud.storage`.

2. **Text Splitter**:
 Splits documents into smaller chunks for efficient processing.

3. **Vector Store**:
 Uses Chroma to store embeddings generated by `VertexAIEmbeddings`.

4. **Flask API**:
 Exposes an endpoint (`/query`) for querying documents.

5. **Vertex AI Integration**:
 Leverages Google's Vertex AI Embeddings and LLMs (e.g., `gemini-pro`) for retrieval-augmented generation.

---

## Example Query Workflow

1. Upload multiple contracts or documents (e.g., PDFs) to your GCS bucket.
2. Deploy or run the RAG agent.
3. Send questions via HTTP POST requests to `/query`.
4. Receive answers based on document content along with source document references.

---

## Notes

- Ensure all required dependencies are installed, including `google-cloud-storage`, `langchain`, `flask`, and `unstructured[pdf]`.
- For large-scale deployments, consider persisting the vector store (e.g., saving it to disk or a database).
- Monitor logs in Google Cloud Console for debugging and performance insights.
-Current dev endpoint for agent is: https://eth-global-service-3968955446.us-central1.run.app/query
-Example request body: {"question": "I'm an artist in the Colombian jurisdiction, can you send me a contract that 	is appropriate for my needs?"}